{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyODO9D6ppT60IGM0PUMb37J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meltyyyyy/kaggle-amex/blob/main/Notebooks/NN/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TN75QOHZi7Np"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    name = \"NN/Transformer\"\n",
        "\n",
        "    n_splits = 5\n",
        "    seed = 2022\n",
        "    target = \"target\"\n",
        "\n",
        "    # Colab Env\n",
        "    upload_from_colab = True\n",
        "    api_path = \"/content/drive/MyDrive/workspace/kaggle.json\"\n",
        "    drive_path = \"/content/drive/MyDrive/workspace/kaggle-amex\"\n",
        "    \n",
        "    # Kaggle Env\n",
        "    kaggle_dataset_path = None\n",
        "    \n",
        "    # Reka Env\n",
        "    dir_path = '/home/abe/kaggle/kaggle-amex'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import warnings\n",
        "import shutil\n",
        "import logging\n",
        "import joblib\n",
        "import random\n",
        "import datetime\n",
        "import sys\n",
        "import gc\n",
        "import multiprocessing\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-pastel')\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "LUw4TAdrjAdh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLAB = \"google.colab\" in sys.modules\n",
        "if COLAB:\n",
        "    print(\"This environment is Google Colab\")\n",
        "    \n",
        "    # mount\n",
        "    from google.colab import drive\n",
        "    if not os.path.isdir(\"/content/drive\"):\n",
        "        drive.mount('/content/drive') \n",
        "\t\n",
        "    # import library\n",
        "    # ! pip install lightgbm==3.3.1\n",
        "    # ! pip install --quiet iterative-stratification\n",
        "    # ! pip install --quiet tensorflow-addons\n",
        "\n",
        "    # use kaggle api (need kaggle token)\n",
        "    f = open(Config.api_path, 'r')\n",
        "    json_data = json.load(f) \n",
        "    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n",
        "    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n",
        "    \n",
        "    # set dirs\n",
        "    DRIVE = Config.drive_path\n",
        "    EXP = (Config.name if Config.name is not None \n",
        "           else get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"][:-6])\n",
        "    NOTEBOOKS = os.path.join(DRIVE, 'Notebooks')\n",
        "    INPUT = os.path.join(DRIVE, \"Input\")\n",
        "    OUTPUT = os.path.join(DRIVE, \"Output\")\n",
        "    SUBMISSION = os.path.join(DRIVE, \"Submission\")\n",
        "    OUTPUT_EXP = os.path.join(OUTPUT, EXP) \n",
        "    EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n",
        "    EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n",
        "    EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n",
        "\n",
        "    # make dirs\n",
        "    for d in [INPUT, SUBMISSION, EXP_MODEL, EXP_FIG, EXP_PREDS]:\n",
        "        os.makedirs(d, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJUdCfumkiFI",
        "outputId": "6bd93933-d750-46ce-987b-7a5ef863fd9e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This environment is Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pynvml\n",
        "\n",
        "pynvml.nvmlInit()\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "device_name = pynvml.nvmlDeviceGetName(handle)\n",
        "\n",
        "if device_name != b'Tesla T4':\n",
        "  raise Exception(\"\"\"\n",
        "    Unfortunately this instance does not have a T4 GPU.\n",
        "    \n",
        "    Please make sure you've configured Colab to request a GPU instance type.\n",
        "    \n",
        "    Sometimes Colab allocates a Tesla K80 instead of a T4. Resetting the instance.\n",
        "\n",
        "    If you get a K80 GPU, try Runtime -> Reset all runtimes...\n",
        "  \"\"\")\n",
        "else:\n",
        "  print('Woo! You got the right kind of GPU!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "baIaUJg1pRSF",
        "outputId": "8e450587-295f-4edd-8fcc-20bdde595620"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-61b86528809e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpynvml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpynvml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvmlInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpynvml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvmlDeviceGetHandleByIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpynvml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvmlDeviceGetName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pynvml'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install RAPIDS\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!bash rapidsai-csp-utils/colab/rapids-colab.sh s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z1fJDJno1oB",
        "outputId": "4c7fb1b0-4454-4c00-ebbe-ce4248fa2fd3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 300, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 300 (delta 74), reused 99 (delta 55), pack-reused 171\u001b[K\n",
            "Receiving objects: 100% (300/300), 87.58 KiB | 5.15 MiB/s, done.\n",
            "Resolving deltas: 100% (136/136), done.\n",
            "PLEASE READ FOR 21.06\n",
            "********************************************************************************************************\n",
            "Another release, another script change.  We had to revise the script, which now:\n",
            "1. Does a more comprehensive install\n",
            "2. Includes BlazingSQL\n",
            "3. is far easier for everyone to understand and maintain\n",
            "\n",
            "The script will require you to add these 5 cells to your notebook.  We have also created a new startup template: \n",
            "https://colab.research.google.com/drive/1TAAi_szMfWqRfHVfjGSqnGVLr_ztzUM9?usp=sharing\n",
            "\n",
            "CHANGES T\n",
            "CELL 1:\n",
            "    # This get the RAPIDS-Colab install files and test check your GPU.  Run cells 1 and 2 only.\n",
            "    # Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
            "    !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
            "    !python rapidsai-csp-utils/colab/env-check.py\n",
            "\n",
            "CELL 2:\n",
            "    # This will update the Colab environment and restart the kernel.\n",
            "    !bash rapidsai-csp-utils/colab/update_gcc.sh\n",
            "    import os\n",
            "    os._exit(00)\n",
            "\n",
            "CELL 3:\n",
            "    ## Installing CondaColab.  This will restart your kernel again\n",
            "    import condacolab\n",
            "    condacolab.install()\n",
            "\n",
            "CELL 4:\n",
            "    import condacolab\n",
            "    condacolab.check()\n",
            "\n",
            "CELL 5:\n",
            "    # Installing RAPIDS is now 'python rapidsai-csp-utils/colab/install_rapids.py <release> <packages>'\n",
            "    # The <release> options are 'stable' and 'nightly'.  Leaving it blank or adding any other words will default to stable.\n",
            "    # The <packages> option are default blank or 'core'.  By default, we install RAPIDSAI and BlazingSQL.  The 'core' option will install only RAPIDSAI and not include BlazingSQL, \n",
            "    !python rapidsai-csp-utils/colab/install_rapids.py nightly\n",
            "    import os\n",
            "    os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
            "    os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
            "    os.environ['CONDA_PREFIX'] = '/usr/local'\n",
            "\n",
            "********************************************************************************************************\n",
            "\n",
            "Enjoy using RAPIDS!  If you have any issues with or suggestions for RAPIDSAI on Colab, please create a issue on https://github.com/rapidsai/rapidsai-csp-utils/issues/new.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cupy, cudf\n",
        "\n",
        "\n",
        "PATH_TO_DATA = '../input/amex-data-for-transformers-and-rnns/data/'\n",
        "\n",
        "# IF YOU WISH TO INFER A MODEL YOU TRAINED OFFLINE\n",
        "# THEN SET TO FALSE AND PROVIDE KAGGLE DATASET URL\n",
        "TRAIN_MODEL = True\n",
        "PATH_TO_MODEL = './model/'\n",
        "\n",
        "INFER_TEST = True\n",
        "\n",
        "print('Using TensorFlow version',tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "jLGutyHXktgB",
        "outputId": "4186d1e3-235c-45da-8578-727db68db5e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2fb27f9745bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudf'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, feat_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"gelu\"), layers.Dense(feat_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "qEI6QamEk54S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_dim = 188\n",
        "embed_dim = 64  # Embedding size for attention\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "dropout_rate = 0.3\n",
        "num_blocks = 2\n",
        "\n",
        "def build_model():\n",
        "    \n",
        "    # INPUT EMBEDDING LAYER\n",
        "    inp = layers.Input(shape=(13,188))\n",
        "    embeddings = []\n",
        "    for k in range(11):\n",
        "        emb = layers.Embedding(10,4)\n",
        "        embeddings.append( emb(inp[:,:,k]) )\n",
        "    x = layers.Concatenate()([inp[:,:,11:]]+embeddings)\n",
        "    x = layers.Dense(feat_dim)(x)\n",
        "    \n",
        "    # TRANSFORMER BLOCKS\n",
        "    for k in range(num_blocks):\n",
        "        x_old = x\n",
        "        transformer_block = TransformerBlock(embed_dim, feat_dim, num_heads, ff_dim, dropout_rate)\n",
        "        x = transformer_block(x)\n",
        "        x = 0.9*x + 0.1*x_old # SKIP CONNECTION\n",
        "    \n",
        "    # CLASSIFICATION HEAD\n",
        "    x = layers.Dense(64, activation=\"relu\")(x[:,-1,:])\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = keras.Model(inputs=inp, outputs=outputs)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    loss = tf.keras.losses.BinaryCrossentropy()\n",
        "    model.compile(loss=loss, optimizer = opt)\n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "ajfdmALalJRu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Wdr3eBlJno",
        "outputId": "a6313e97-eb77-4d56-916d-65d4f7c56d22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 13, 188)]    0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_38 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_39 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_40 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_41 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_42 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_43 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_44 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_45 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_46 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_47 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_48 (S  (None, 13)          0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_49 (S  (None, 13, 177)     0           ['input_4[0][0]']                \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " embedding_33 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_38[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_34 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_39[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_35 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_40[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_36 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_41[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_37 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_42[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_38 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_43[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_39 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_44[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_40 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_45[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_41 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_46[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_42 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_47[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " embedding_43 (Embedding)       (None, 13, 4)        40          ['tf.__operators__.getitem_48[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 13, 221)      0           ['tf.__operators__.getitem_49[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'embedding_33[0][0]',           \n",
            "                                                                  'embedding_34[0][0]',           \n",
            "                                                                  'embedding_35[0][0]',           \n",
            "                                                                  'embedding_36[0][0]',           \n",
            "                                                                  'embedding_37[0][0]',           \n",
            "                                                                  'embedding_38[0][0]',           \n",
            "                                                                  'embedding_39[0][0]',           \n",
            "                                                                  'embedding_40[0][0]',           \n",
            "                                                                  'embedding_41[0][0]',           \n",
            "                                                                  'embedding_42[0][0]',           \n",
            "                                                                  'embedding_43[0][0]']           \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 13, 188)      41736       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " transformer_block_4 (Transform  (None, 13, 188)     242664      ['dense_17[0][0]']               \n",
            " erBlock)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 13, 188)     0           ['transformer_block_4[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply_9 (TFOpLambda  (None, 13, 188)     0           ['dense_17[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 13, 188)     0           ['tf.math.multiply_8[0][0]',     \n",
            " mbda)                                                            'tf.math.multiply_9[0][0]']     \n",
            "                                                                                                  \n",
            " transformer_block_5 (Transform  (None, 13, 188)     242664      ['tf.__operators__.add_4[0][0]'] \n",
            " erBlock)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (None, 13, 188)     0           ['transformer_block_5[0][0]']    \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (None, 13, 188)     0           ['tf.__operators__.add_4[0][0]'] \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 13, 188)     0           ['tf.math.multiply_10[0][0]',    \n",
            " mbda)                                                            'tf.math.multiply_11[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_50 (S  (None, 188)         0           ['tf.__operators__.add_5[0][0]'] \n",
            " licingOpLambda)                                                                                  \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 64)           12096       ['tf.__operators__.getitem_50[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 32)           2080        ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 1)            33          ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 541,713\n",
            "Trainable params: 541,713\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "LR_START = 1e-6\n",
        "LR_MAX = 1e-3\n",
        "LR_MIN = 1e-6\n",
        "LR_RAMPUP_EPOCHS = 0\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "EPOCHS = 8\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n",
        "        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
        "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
        "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
        "    return lr\n",
        "\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "lr_y = [lrfn(x) for x in rng]\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(rng, lr_y, '-o')\n",
        "plt.xlabel('Epoch'); plt.ylabel('LR')\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(lr_y[0], max(lr_y), lr_y[-1]))\n",
        "LR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "gP3N4Fu6lnUt",
        "outputId": "9df41f27-95f9-4298-c158-084d9cadf1c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate schedule: 0.001 to 0.001 to 1e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPETITION METRIC FROM Konstantin Yakovlev\n",
        "# https://www.kaggle.com/kyakovlev\n",
        "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
        "def amex_metric_mod(y_true, y_pred):\n",
        "\n",
        "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz        = cum_pos_found / total_pos\n",
        "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
        "\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)"
      ],
      "metadata": {
        "id": "HKmYzUK6m5Ne"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN_MODEL:\n",
        "    # SAVE TRUE AND OOF\n",
        "    true = np.array([])\n",
        "    oof = np.array([])\n",
        "    VERBOSE = 2 # use 1 for interactive \n",
        "\n",
        "    for fold in range(5):\n",
        "\n",
        "        # INDICES OF TRAIN AND VALID FOLDS\n",
        "        valid_idx = [2*fold+1, 2*fold+2]\n",
        "        train_idx = [x for x in [1,2,3,4,5,6,7,8,9,10] if x not in valid_idx]\n",
        "\n",
        "        print('#'*25)\n",
        "        print(f'### Fold {fold+1} with valid files', valid_idx)\n",
        "\n",
        "        # READ TRAIN DATA FROM DISK\n",
        "        X_train = []; y_train = []\n",
        "        for k in train_idx:\n",
        "            X_train.append( np.load(f'{PATH_TO_DATA}data_{k}.npy'))\n",
        "            y_train.append( pd.read_parquet(f'{PATH_TO_DATA}targets_{k}.pqt') )\n",
        "        X_train = np.concatenate(X_train,axis=0)\n",
        "        y_train = pd.concat(y_train).target.values\n",
        "        print('### Training data shapes', X_train.shape, y_train.shape)\n",
        "\n",
        "        # READ VALID DATA FROM DISK\n",
        "        X_valid = []; y_valid = []\n",
        "        for k in valid_idx:\n",
        "            X_valid.append( np.load(f'{PATH_TO_DATA}data_{k}.npy'))\n",
        "            y_valid.append( pd.read_parquet(f'{PATH_TO_DATA}targets_{k}.pqt') )\n",
        "        X_valid = np.concatenate(X_valid,axis=0)\n",
        "        y_valid = pd.concat(y_valid).target.values\n",
        "        print('### Validation data shapes', X_valid.shape, y_valid.shape)\n",
        "        print('#'*25)\n",
        "\n",
        "        # BUILD AND TRAIN MODEL\n",
        "        K.clear_session()\n",
        "        model = build_model()\n",
        "        h = model.fit(X_train,y_train, \n",
        "                      validation_data = (X_valid,y_valid),\n",
        "                      batch_size=512, epochs=EPOCHS, verbose=VERBOSE,\n",
        "                      callbacks = [LR])\n",
        "        if not os.path.exists(PATH_TO_MODEL): os.makedirs(PATH_TO_MODEL)\n",
        "        model.save_weights(f'{PATH_TO_MODEL}transformer_fold_{fold+1}.h5')\n",
        "\n",
        "        # INFER VALID DATA\n",
        "        print('Inferring validation data...')\n",
        "        p = model.predict(X_valid, batch_size=512, verbose=VERBOSE).flatten()\n",
        "\n",
        "        print()\n",
        "        print(f'Fold {fold+1} CV=', amex_metric_mod(y_valid, p) )\n",
        "        print()\n",
        "        true = np.concatenate([true, y_valid])\n",
        "        oof = np.concatenate([oof, p])\n",
        "        \n",
        "        # CLEAN MEMORY\n",
        "        del model, X_train, y_train, X_valid, y_valid, p\n",
        "        gc.collect()\n",
        "\n",
        "    # PRINT OVERALL RESULTS\n",
        "    print('#'*25)\n",
        "    print(f'Overall CV =', amex_metric_mod(true, oof) )"
      ],
      "metadata": {
        "id": "a4ywNn5InGAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if INFER_TEST:\n",
        "    # BUILD MODEL\n",
        "    K.clear_session()\n",
        "    model = build_model()\n",
        "    \n",
        "    # LOAD SAMPLE SUBMISSION\n",
        "    start = 0; end = 0\n",
        "    sub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')\n",
        "    \n",
        "    # REARANGE SUB ROWS TO MATCH 20 TEST FILES\n",
        "    sub['hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
        "    test_hash_index = cupy.load(f'{PATH_TO_DATA}test_hashes_data.npy')\n",
        "    sub = sub.set_index('hash').loc[test_hash_index].reset_index(drop=True)\n",
        "    \n",
        "    for k in range(20):\n",
        "        print(f'Inferring Test_File_{k+1}')\n",
        "        X_test = np.load(f'{PATH_TO_DATA}test_data_{k+1}.npy')\n",
        "        end = start + X_test.shape[0]\n",
        "\n",
        "        # INFER 5 FOLD MODELS\n",
        "        model.load_weights(f'{PATH_TO_MODEL}transformer_fold_1.h5')\n",
        "        p = model.predict(X_test, batch_size=512, verbose=0).flatten() \n",
        "        for j in range(1,5):\n",
        "            model.load_weights(f'{PATH_TO_MODEL}transformer_fold_{j+1}.h5')\n",
        "            p += model.predict(X_test, batch_size=512, verbose=0).flatten()\n",
        "        p /= 5.0\n",
        "\n",
        "        sub.loc[start:end-1,'prediction'] = p\n",
        "        start = end"
      ],
      "metadata": {
        "id": "oO5e1jLynm-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}