{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    name = \"EDA/Agg-RFE\"\n",
    "\n",
    "    n_splits = 5\n",
    "    seed = 2022\n",
    "    target = \"target\"\n",
    "\n",
    "    # Colab Env\n",
    "    upload_from_colab = True\n",
    "    api_path = \"/content/drive/MyDrive/workspace/kaggle.json\"\n",
    "    drive_path = \"/content/drive/MyDrive/workspace/kaggle-amex\"\n",
    "\n",
    "    # Kaggle Env\n",
    "    kaggle_dataset_path = None\n",
    "\n",
    "    # Reka Env\n",
    "    dir_path = '/home/abe/kaggle/kaggle-amex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import shutil\n",
    "import logging\n",
    "import joblib\n",
    "import random\n",
    "import datetime\n",
    "import sys\n",
    "import gc\n",
    "import multiprocessing\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from IPython import get_ipython\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = os.path.join(Config.dir_path, 'input')\n",
    "OUTPUT = os.path.join(Config.dir_path, 'output')\n",
    "SUBMISSION = os.path.join(Config.dir_path, 'submissions')\n",
    "OUTPUT_EXP = os.path.join(OUTPUT, Config.name)\n",
    "EXP_MODEL = os.path.join(OUTPUT_EXP, \"model\")\n",
    "EXP_FIG = os.path.join(OUTPUT_EXP, \"fig\")\n",
    "EXP_PREDS = os.path.join(OUTPUT_EXP, \"preds\")\n",
    "\n",
    "# make dirs\n",
    "for d in [INPUT, SUBMISSION, EXP_MODEL, EXP_FIG, EXP_PREDS]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(os.path.join(INPUT, 'train_agg.pkl'), compression='gzip')\n",
    "test = pd.read_pickle(os.path.join(INPUT, 'test_agg.pkl'), compression='gzip')\n",
    "train = train.sample(10000)\n",
    "test = test.sample(15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "CategoricalIndex: 10000 entries, a728d85084a40e92bc5d76204de756ea36383417f8fee4672defcf258570b1da to 0d70a858b5a48194c828610b3d5ca553968a4e5fddf75ea03f8413d0545037ed\n",
      "Columns: 919 entries, P_2_mean to target\n",
      "dtypes: category(2), float16(713), float64(178), int64(22), int8(4)\n",
      "memory usage: 48.6 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>...</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a728d85084a40e92bc5d76204de756ea36383417f8fee4672defcf258570b1da</th>\n",
       "      <td>0.676270</td>\n",
       "      <td>0.105620</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>0.619629</td>\n",
       "      <td>0.369141</td>\n",
       "      <td>0.269638</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.915527</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59257d6f5b98f5fa7f9</th>\n",
       "      <td>0.446533</td>\n",
       "      <td>0.082594</td>\n",
       "      <td>0.330811</td>\n",
       "      <td>0.538574</td>\n",
       "      <td>0.538574</td>\n",
       "      <td>0.337891</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>0.008835</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>U</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534c76f47b617457a7c9</th>\n",
       "      <td>0.944824</td>\n",
       "      <td>0.023044</td>\n",
       "      <td>0.908691</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>0.908691</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>0.266927</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.677734</td>\n",
       "      <td>0.589355</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef86b680f200eb37a24ee52d187c2b73d8759c123948f4ddf32a8b5cc5209844</th>\n",
       "      <td>0.401855</td>\n",
       "      <td>0.118077</td>\n",
       "      <td>0.113647</td>\n",
       "      <td>0.514160</td>\n",
       "      <td>0.113647</td>\n",
       "      <td>0.063782</td>\n",
       "      <td>0.134368</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.478271</td>\n",
       "      <td>0.064087</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1f3862359e8e5860fec2d2767404f32163eea836da56a1a123bce7402dd5def5</th>\n",
       "      <td>0.604980</td>\n",
       "      <td>0.081648</td>\n",
       "      <td>0.375244</td>\n",
       "      <td>0.702148</td>\n",
       "      <td>0.696289</td>\n",
       "      <td>0.186401</td>\n",
       "      <td>0.280836</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.915039</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    P_2_mean   P_2_std  \\\n",
       "customer_ID                                                              \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...  0.676270  0.105620   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...  0.446533  0.082594   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...  0.944824  0.023044   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...  0.401855  0.118077   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...  0.604980  0.081648   \n",
       "\n",
       "                                                     P_2_min   P_2_max  \\\n",
       "customer_ID                                                              \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...  0.542969  0.827637   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...  0.330811  0.538574   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...  0.908691  0.979492   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...  0.113647  0.514160   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...  0.375244  0.702148   \n",
       "\n",
       "                                                    P_2_last  D_39_mean  \\\n",
       "customer_ID                                                               \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...  0.619629   0.369141   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...  0.538574   0.337891   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...  0.908691   0.270020   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...  0.113647   0.063782   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...  0.696289   0.186401   \n",
       "\n",
       "                                                    D_39_std  D_39_min  \\\n",
       "customer_ID                                                              \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...  0.269638  0.003632   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...  0.329613  0.000892   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...  0.266927  0.000709   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...  0.134368  0.004238   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...  0.280836  0.002653   \n",
       "\n",
       "                                                    D_39_max  D_39_last  ...  \\\n",
       "customer_ID                                                              ...   \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...  0.915527   0.003632  ...   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...  0.862305   0.008835  ...   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...  0.677734   0.589355  ...   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...  0.478271   0.064087  ...   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...  0.915039   0.002653  ...   \n",
       "\n",
       "                                                    D_64_count  D_64_last  \\\n",
       "customer_ID                                                                 \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...          13          O   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...          13          U   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...          13          O   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...          11          O   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...          11          O   \n",
       "\n",
       "                                                    D_64_nunique  D_66_count  \\\n",
       "customer_ID                                                                    \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...             1          13   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...             2           0   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...             1           0   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...             1           0   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...             1           0   \n",
       "\n",
       "                                                    D_66_last  D_66_nunique  \\\n",
       "customer_ID                                                                   \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...        1.0             1   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...        NaN             0   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...        NaN             0   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...        NaN             0   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...        NaN             0   \n",
       "\n",
       "                                                    D_68_count  D_68_last  \\\n",
       "customer_ID                                                                 \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...          13        5.0   \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...          13        6.0   \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...          13        6.0   \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...          11        6.0   \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...          11        6.0   \n",
       "\n",
       "                                                    D_68_nunique  target  \n",
       "customer_ID                                                               \n",
       "a728d85084a40e92bc5d76204de756ea36383417f8fee46...             1       0  \n",
       "52f7455e4fd9b07b60f1c8a572e37972aa9e969ab2f8b59...             2       1  \n",
       "fdd72c75e5e7fe9ba0283fb993f6df9b2f20fbdd287e534...             1       0  \n",
       "ef86b680f200eb37a24ee52d187c2b73d8759c123948f4d...             1       1  \n",
       "1f3862359e8e5860fec2d2767404f32163eea836da56a1a...             1       0  \n",
       "\n",
       "[5 rows x 919 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wwBWY1fdnxFw"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/inversion/amex-competition-metric-python\n",
    "\n",
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def lgb_amex_metric(y_true, y_pred):\n",
    "    \"\"\"The competition metric with lightgbm's calling convention\"\"\"\n",
    "    return ('amex',\n",
    "            amex_metric(pd.DataFrame({'target': y_true}), pd.Series(y_pred, name='prediction')),\n",
    "            True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "CategoricalIndex: 10000 entries, a728d85084a40e92bc5d76204de756ea36383417f8fee4672defcf258570b1da to 0d70a858b5a48194c828610b3d5ca553968a4e5fddf75ea03f8413d0545037ed\n",
      "Columns: 919 entries, P_2_mean to target\n",
      "dtypes: category(2), float16(713), float64(178), int64(22), int8(4)\n",
      "memory usage: 48.6 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "CategoricalIndex: 15000 entries, 7e1ce7131c3e15238564c77ff26045f0d799714d7ce91830ad162be0942b3160 to caa1eb02f9006b8ed10497801923332504ab22bec741057ad299412297e0b15a\n",
      "Columns: 918 entries, P_2_mean to D_68_nunique\n",
      "dtypes: category(2), float16(713), float64(178), int32(3), int64(22)\n",
      "memory usage: 82.8 MB\n",
      "None\n",
      "\n",
      "-------------------------------------------------- data type transformation --------------------------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "CategoricalIndex: 10000 entries, a728d85084a40e92bc5d76204de756ea36383417f8fee4672defcf258570b1da to 0d70a858b5a48194c828610b3d5ca553968a4e5fddf75ea03f8413d0545037ed\n",
      "Columns: 919 entries, P_2_mean to target\n",
      "dtypes: category(2), float16(891), int8(26)\n",
      "memory usage: 36.9 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "CategoricalIndex: 15000 entries, 7e1ce7131c3e15238564c77ff26045f0d799714d7ce91830ad162be0942b3160 to caa1eb02f9006b8ed10497801923332504ab22bec741057ad299412297e0b15a\n",
      "Columns: 918 entries, P_2_mean to D_68_nunique\n",
      "dtypes: category(2), float16(891), int8(25)\n",
      "memory usage: 65.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "float64_cols = [col for col in train.columns if train[col].dtype == 'float64']\n",
    "int64_cols = [col for col in train.columns if train[col].dtype == 'int64']\n",
    "\n",
    "print(train.info())\n",
    "print(test.info())\n",
    "print()\n",
    "print(\"-\"*50+f' data type transformation '+'-'*50)\n",
    "print()\n",
    "\n",
    "def transform_dtype(df):\n",
    "  for col in df.columns:\n",
    "    if df[col].dtype == 'float64':\n",
    "      df[col] = df[col].astype('float16')\n",
    "    if df[col].dtype == 'float32':\n",
    "      df[col] = df[col].astype('float16')\n",
    "    if df[col].dtype == 'int64':\n",
    "      df[col] = df[col].astype('int8')\n",
    "    if df[col].dtype == 'int32':\n",
    "      df[col] = df[col].astype('int8')\n",
    "  return df\n",
    "\n",
    "train = transform_dtype(train)\n",
    "test = transform_dtype(test)\n",
    "\n",
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cat_cols = [col for col in train.columns if train[col].dtype == 'category']\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[col])\n",
    "    train[col] = le.transform(train[col])\n",
    "    test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "unuse = ['target', 'customer_ID', 'S_2']\n",
    "\n",
    "for col in train.columns:\n",
    "  if col not in unuse:\n",
    "    features.append(col)\n",
    "\n",
    "# print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train[features].values, train[Config.target].values,\n",
    "                 train_size=0.8, \n",
    "                 random_state=Config.seed, \n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 918 features.\n",
      "Fitting estimator with 914 features.\n",
      "Fitting estimator with 910 features.\n",
      "Fitting estimator with 906 features.\n",
      "Fitting estimator with 902 features.\n",
      "Fitting estimator with 898 features.\n",
      "Fitting estimator with 894 features.\n",
      "Fitting estimator with 890 features.\n",
      "Fitting estimator with 886 features.\n",
      "Fitting estimator with 882 features.\n",
      "Fitting estimator with 878 features.\n",
      "Fitting estimator with 874 features.\n",
      "Fitting estimator with 870 features.\n",
      "Fitting estimator with 866 features.\n",
      "Fitting estimator with 862 features.\n",
      "Fitting estimator with 858 features.\n",
      "Fitting estimator with 854 features.\n",
      "Fitting estimator with 850 features.\n",
      "Fitting estimator with 846 features.\n",
      "Fitting estimator with 842 features.\n",
      "Fitting estimator with 838 features.\n",
      "Fitting estimator with 834 features.\n",
      "Fitting estimator with 830 features.\n",
      "Fitting estimator with 826 features.\n",
      "Fitting estimator with 822 features.\n",
      "Fitting estimator with 818 features.\n",
      "Fitting estimator with 814 features.\n",
      "Fitting estimator with 810 features.\n",
      "Fitting estimator with 806 features.\n",
      "Fitting estimator with 802 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LGBMClassifier(force_col_wise=True, learning_rate=0.01,\n",
       "                             min_child_samples=2400, n_estimators=10000,\n",
       "                             n_jobs=32, num_leaves=127, objective='binary',\n",
       "                             random_state=2022, verbose=-1),\n",
       "    n_features_to_select=800, step=4, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "\n",
    "lgb_params = {\"learning_rate\": 0.01,\n",
    "              'num_leaves': 127,\n",
    "              'min_child_samples': 2400}\n",
    "\n",
    "fit_params = {\n",
    "    'callbacks': [early_stopping(stopping_rounds=10, verbose=0)],\n",
    "    'eval_set': [(X_test, y_test)],\n",
    "    'eval_metric': lgb_amex_metric,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "model = LGBMClassifier(**lgb_params,\n",
    "                       boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       n_estimators=10000,\n",
    "                       random_state=Config.seed,\n",
    "                       force_col_wise=True,\n",
    "                       n_jobs=32,\n",
    "                       verbose=-1)\n",
    "\n",
    "rfe = RFE(model,\n",
    "          n_features_to_select=150,\n",
    "          step=4,\n",
    "          verbose=1)\n",
    "\n",
    "rfe.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = pd.DataFrame(rfe.transform(train[features]), \n",
    "                     columns=train[features].columns.values[rfe.get_support()])\n",
    "result = pd.DataFrame(rfe.get_support(), index=train[features].columns.values, columns=['used'])\n",
    "result['ranking'] = rfe.ranking_\n",
    "result = result.sort_values('ranking', ascending=True).rename({result.index.name: 'feature'}).reset_index(drop=False).rename({'index': 'feature'}, axis=1)\n",
    "result.to_csv(f'{EXP_MODEL}/rfe_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.plotting import plot_metric\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def fit_lgbm(X, y, params=None):\n",
    "  models = []\n",
    "  scores = []\n",
    "\n",
    "  skf = StratifiedKFold(n_splits=Config.n_splits, shuffle=True, random_state=Config.seed)\n",
    "  \n",
    "  for fold, (train_indices, valid_indices) in enumerate(tqdm(skf.split(X, y))):\n",
    "    print(\"-\"*50+f' fold{fold} '+'-'*50)\n",
    "    X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "    X_valid, y_valid = X.iloc[valid_indices], y.iloc[valid_indices]\n",
    "\n",
    "    model = LGBMClassifier(**params,\n",
    "                           boosting_type='gbdt',\n",
    "                           objective='binary',\n",
    "                           n_estimators=10000,\n",
    "                           random_state=Config.seed,\n",
    "                           force_col_wise=True,\n",
    "                           n_jobs=32,\n",
    "                           verbose=-1)\n",
    "    \n",
    "    model.fit(X_train, y_train, \n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              eval_names=['train', 'valid'],\n",
    "              eval_metric=lgb_amex_metric,\n",
    "              callbacks=[early_stopping(stopping_rounds=10, verbose=0)],\n",
    "              verbose=50)\n",
    "    \n",
    "    # ------------------- prediction -------------------\n",
    "    pred = model.predict_proba(X_valid)[:, 1]\n",
    "    score = amex_metric(pd.DataFrame({'target': y_valid.values}), pd.Series(pred, name='prediction'))\n",
    "\n",
    "    # ------------------- plot -------------------\n",
    "    plot_metric(model)\n",
    "\n",
    "    # ------------------- save -------------------\n",
    "    file = f'{EXP_MODEL}/lgbm_fold{fold}.pkl'\n",
    "    joblib.dump(model, file)\n",
    "    scores.append(score)\n",
    "    models.append(model)\n",
    "    print(f'fold{fold} amex meric: {score}')\n",
    "    print()\n",
    "\n",
    "  print(f\"OOF Score: {np.mean(scores):.5f}\")\n",
    "  return models\n",
    "\n",
    "def inference_lgbm(models, X):\n",
    "    pred = np.array([model.predict_proba(X) for model in models])\n",
    "    pred = np.mean(pred, axis=0)[:, 1]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv(f'{EXP_MODEL}/rfe_features.csv')\n",
    "features = feature_df[feature_df['used'] == True].loc[:, 'feature'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\"learning_rate\": 0.01,\n",
    "              'num_leaves': 127,\n",
    "              'min_child_samples': 2400}\n",
    "\n",
    "models = fit_lgbm(train[features], train[Config.target], params=lgb_params)\n",
    "# models = [joblib.load(f'{EXP_MODEL}/lgbm_fold{i}.pkl') for i in range(Config.n_splits)]\n",
    "pred = inference_lgbm(models, test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importances(models):\n",
    "    importance_df = pd.DataFrame(models[0].feature_importances_, \n",
    "                                 index=features, \n",
    "                                 columns=['importance'])\\\n",
    "                        .sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    plt.subplots(figsize=(len(features) // 4, 5))\n",
    "    plt.bar(importance_df.index, importance_df.importance)\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_importances(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'customer_ID': test.index,\n",
    "                    'prediction': pred})\n",
    "sub.to_csv(f'{EXP_PREDS}/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions submit -c amex-default-prediction -f /home/abe/kaggle/kaggle-amex/submissions/submission.csv -m \"Recuresive Feature Elimination for Aggregation Features\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29001d83105739b7e7991894c59ca9a685d5fb80e48bd2a6126a67de75b87e20"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('amex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
